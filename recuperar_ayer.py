import logging
from tasks.scraper.order_scraper import OrderScraper
from tasks.celery_tasks import process_drone_data
from tasks.scraper.drone_scraper import DroneScraper
from app.db.session import SessionLocal

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_recovery():
    print("ğŸš€ Iniciando recuperaciÃ³n de Ãºltimas 48 horas...")
    
    ls = OrderScraper()
    if not ls.login(): return

    # Leemos 10 pÃ¡ginas para asegurar que agarramos todo lo de ayer
    print("ğŸ“„ Escaneando Ãºltimas 10 pÃ¡ginas...")
    items = ls.get_historical_ids(max_pages=10) 
    ls.close_driver()
    
    print(f"ğŸ“¦ Encontrados {len(items)} pedidos recientes. Procesando faltantes...")

    db = SessionLocal()
    drone = DroneScraper()
    if not drone.login(): return

    count = 0
    for item in items:
        eid = item['id']
        duration = item['duration']
        
        # Entramos SIEMPRE para asegurar que tenga la data correcta
        print(f"ğŸ” ({count+1}/{len(items)}) Verificando #{eid}...")
        data = drone.scrape_detail(eid, mode='full')
        data['duration_text'] = duration # Inyectamos duraciÃ³n de lista
        
        process_drone_data(db, data)
        count += 1

    drone.close_driver()
    db.close()
    print("âœ… RecuperaciÃ³n finalizada.")

if __name__ == "__main__":
    run_recovery()
